# basic_00_forecasting

<a target="_blank" href="https://cookiecutter-data-science.drivendata.org/">
    <img src="https://img.shields.io/badge/CCDS-Project%20template-328F97?logo=cookiecutter" />
</a>

A short description of the project.

## Project Organization

```
‚îú‚îÄ‚îÄ LICENSE            <- Open-source license if one is chosen
‚îú‚îÄ‚îÄ Makefile           <- Makefile with convenience commands like `make data` or `make train`
‚îú‚îÄ‚îÄ README.md          <- The top-level README for developers using this project.
‚îú‚îÄ‚îÄ data
‚îÇ   ‚îú‚îÄ‚îÄ external       <- Data from third party sources.
‚îÇ   ‚îú‚îÄ‚îÄ interim        <- Intermediate data that has been transformed.
‚îÇ   ‚îú‚îÄ‚îÄ processed      <- The final, canonical data sets for modeling.
‚îÇ   ‚îî‚îÄ‚îÄ raw            <- The original, immutable data dump.
‚îÇ
‚îú‚îÄ‚îÄ docs               <- A default mkdocs project; see www.mkdocs.org for details
‚îÇ
‚îú‚îÄ‚îÄ models             <- Trained and serialized models, model predictions, or model summaries
‚îÇ
‚îú‚îÄ‚îÄ notebooks          <- Jupyter notebooks. Naming convention is a number (for ordering),
‚îÇ                         the creator's initials, and a short `-` delimited description, e.g.
‚îÇ                         `1.0-jqp-initial-data-exploration`.
‚îÇ
‚îú‚îÄ‚îÄ pyproject.toml     <- Project configuration file with package metadata for 
‚îÇ                         ai_workflow_engine and configuration for tools like black
‚îÇ
‚îú‚îÄ‚îÄ references         <- Data dictionaries, manuals, and all other explanatory materials.
‚îÇ
‚îú‚îÄ‚îÄ reports            <- Generated analysis as HTML, PDF, LaTeX, etc.
‚îÇ   ‚îî‚îÄ‚îÄ figures        <- Generated graphics and figures to be used in reporting
‚îÇ
‚îú‚îÄ‚îÄ requirements.txt   <- The requirements file for reproducing the analysis environment, e.g.
‚îÇ                         generated with `pip freeze > requirements.txt`
‚îÇ
‚îú‚îÄ‚îÄ setup.cfg          <- Configuration file for flake8
‚îÇ
‚îî‚îÄ‚îÄ clustering_workflow_engine   <- Source code for use in this project.
    ‚îÇ
    ‚îú‚îÄ‚îÄ __init__.py             <- Makes ai_workflow_engine a Python module
    ‚îÇ
    ‚îú‚îÄ‚îÄ config.py               <- Store useful variables and configuration
    ‚îÇ
    ‚îú‚îÄ‚îÄ dataset.py              <- Scripts to download or generate data
    ‚îÇ
    ‚îú‚îÄ‚îÄ experiments                
    ‚îÇ   ‚îî‚îÄ‚îÄ mlflow_utils.py     <- Utilities for MLflow integration: functions to start experiments, log parameters, metrics, and trained models
    ‚îÇ
    ‚îú‚îÄ‚îÄ features.py             <- Code to create features for modeling
    ‚îÇ
    ‚îú‚îÄ‚îÄ modeling                
    ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py 
    ‚îÇ   ‚îú‚îÄ‚îÄ predict.py              <- Code to run model inference with trained models          
    ‚îÇ   ‚îú‚îÄ‚îÄtrain.py                 <- High-level script to train models, handle datasets, and orchestrate the training pipeline
    ‚îÇ   ‚îú‚îÄ‚îÄtrainer.py               <- Functions to train models, perform cross-validation, and log parameters, metrics, and models to MLflow
    ‚îÇ   ‚îî‚îÄ‚îÄ hyperparam_optimization.py <- Functions to perform hyperparameter optimization using Optuna
    ‚îÇ
    ‚îú‚îÄ‚îÄ pipeline.py             <- High-level pipeline script to run the full workflow: data preprocessing, model training, hyperparameter optimization, evaluation, and MLflow logging
    ‚îî‚îÄ‚îÄ plots.py                <- Code to create visualizations
```

# Pipeline de Treinamento de Modelos com MLflow

Projeto b√°sico de _Forecasting_ utilizando o Arima e Prophet para fins de aprendizado e experimenta√ß√£o com pipelines para problemas de s√©ries temporais.  
O objetivo √© construir, treinar e avaliar uma rede simples utilizando dados sint√©ticos com suporte a *logging* e *monitoramento* estruturado, utilizando  `Optuna` e `MLflow`.


O pipeline est√° estruturado para ser executado via terminal, usando Typer, com todos os par√¢metros em **kebab-case**.

---
# Executando o pipeline
## Comando base
```bash
python pipeline.py [OPTIONS]
```

## ‚öôÔ∏è Op√ß√µes principais

| Par√¢metro        | Tipo | Padr√£o          | Descri√ß√£o                                                                 |
| ---------------- | ---- | --------------- | ------------------------------------------------------------------------- |
| `--dataset-name` | str  | "air_passengers"| Nome do dataset dispon√≠vel em `dataset.py` ou no diret√≥rio `data/`       |
| `--model-type`   | str  | "Prophet"       | Tipo de modelo a ser treinado: `"Prophet"` ou `"Arima"`                   |
| `--optimize-params` | bool | False         | Se `True`, executa otimiza√ß√£o de hiperpar√¢metros com Optuna              |
| `--n-trials`     | int  | 20              | N√∫mero de itera√ß√µes da otimiza√ß√£o (usado quando `--optimize-params=True`) |
| `--task`         | str  | "forecasting"   | Tipo de tarefa do pipeline (atualmente `"forecasting"`)                  |

> ‚ö†Ô∏è **Importante:** use **kebab-case** no terminal (`--dataset-name`) e **n√£o** `snake_case` (`--dataset_name`).

---

## üöÄ Exemplos de execu√ß√£o

| Dataset         | Modelo     | Comando                                                                                     |
| ---------------- | ----------- | ------------------------------------------------------------------------------------------- |
| Air Passengers   | Prophet    | `python -m forecasting_workflow_engine.modeling.train --dataset-name air_passengers --model-type Prophet` |
| Air Passengers   | AutoARIMA  | `python -m forecasting_workflow_engine.modeling.train --dataset-name air_passengers --model-type Arima` |
| Air Passengers   | Prophet (otimizado) | `python -m forecasting_workflow_engine.modeling.train --dataset-name air_passengers --model-type Prophet --optimize-params True --n-trials 20` |
| Air Passengers   | AutoARIMA (via pipeline) | `python -m forecasting_workflow_engine.pipelines.pipeline --dataset-name air_passengers --model-type Arima` |

---

## üí° Dica
Se preferir rodar todos os experimentos em sequ√™ncia e registrar automaticamente no MLflow:

```bash
python -m forecasting_workflow_engine.pipelines.pipeline --dataset-name air_passengers --model-type Prophet
```
> ‚ö†Ô∏è Importante: Use kebab-case no terminal (--dataset-name) e n√£o snake_case (--dataset_name).

## üí° Dica 2
Execute o notebook para acessar an√°lises iniciais

## üìö Refer√™ncias
### S√©ries temporais, Prophet, Arima

1. **Taylor, S. J.; Letham, B.** Forecasting at scale. *The American Statistician*, v. 72, n. 1, p. 37‚Äì45, 2018.
2. **Hyndman, R. J.; Athanasopoulos, G.** Forecasting: Principles and Practice. 3. ed. Melbourne: OTexts, 2021. Dispon√≠vel em: [https://otexts.com/fpp3/](https://otexts.com/fpp3/).
3. **Box, G. E. P.; Jenkins, G. M.; Reinsel, G. C.; Ljung, G. M.** Time Series Analysis: Forecasting and Control. 5. ed. Hoboken: John Wiley & Sons, 2015.
4. **Meta (Facebook Research).** Prophet: Forecasting at Scale ‚Äî Official Documentation. 2025. Dispon√≠vel em: [https://facebook.github.io/prophet/](https://facebook.github.io/prophet/).
5. **Pellegrini, T.; Baeza-Yates, R.; Barbosa, L.** AutoARIMA: Model Selection and Hyperparameter Optimization for ARIMA. *pmdarima Documentation*, 2025. Dispon√≠vel em: [https://alkaline-ml.com/pmdarima/](https://alkaline-ml.com/pmdarima/).
6. **Shumway, R. H.; Stoffer, D. S.** Time Series Analysis and Its Applications: With R Examples. 4. ed. Springer, 2017.
7. **Chatfield, C.** The Analysis of Time Series: An Introduction. 6. ed. Chapman and Hall/CRC, 2003.
8. **Zhang, G.** Time series forecasting using a hybrid ARIMA and neural network model. *Neurocomputing*, v. 50, p. 159‚Äì175, 2003.


### Otimiza√ß√£o de Hiperpar√¢metros (Optuna)
5. Akiba, T., Sano, S., Yanase, T., Ohta, T., & Koyama, M. (2019). *Optuna: A Next-generation Hyperparameter Optimization Framework*. Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining (KDD‚Äô19).  
6. [Optuna Official Documentation](https://optuna.org/)

### MLflow
7. Zaharia, M., Chen, A., Davidson, A., Ghodsi, A., Hong, M., Konwinski, A., ‚Ä¶ & Stoica, I. (2018). *Accelerating the Machine Learning Lifecycle with MLflow*. IEEE Data Engineering Bulletin.  
8. [MLflow Official Documentation](https://mlflow.org/)
