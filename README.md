# basic_00_forecasting

<a target="_blank" href="https://cookiecutter-data-science.drivendata.org/">
    <img src="https://img.shields.io/badge/CCDS-Project%20template-328F97?logo=cookiecutter" />
</a>

A short description of the project.

## Project Organization

```
‚îú‚îÄ‚îÄ LICENSE            <- Open-source license if one is chosen
‚îú‚îÄ‚îÄ Makefile           <- Makefile with convenience commands like `make data` or `make train`
‚îú‚îÄ‚îÄ README.md          <- The top-level README for developers using this project.
‚îú‚îÄ‚îÄ data
‚îÇ   ‚îú‚îÄ‚îÄ external       <- Data from third party sources.
‚îÇ   ‚îú‚îÄ‚îÄ interim        <- Intermediate data that has been transformed.
‚îÇ   ‚îú‚îÄ‚îÄ processed      <- The final, canonical data sets for modeling.
‚îÇ   ‚îî‚îÄ‚îÄ raw            <- The original, immutable data dump.
‚îÇ
‚îú‚îÄ‚îÄ docs               <- A default mkdocs project; see www.mkdocs.org for details
‚îÇ
‚îú‚îÄ‚îÄ models             <- Trained and serialized models, model predictions, or model summaries
‚îÇ
‚îú‚îÄ‚îÄ notebooks          <- Jupyter notebooks. Naming convention is a number (for ordering),
‚îÇ                         the creator's initials, and a short `-` delimited description, e.g.
‚îÇ                         `1.0-jqp-initial-data-exploration`.
‚îÇ
‚îú‚îÄ‚îÄ pyproject.toml     <- Project configuration file with package metadata for 
‚îÇ                         ai_workflow_engine and configuration for tools like black
‚îÇ
‚îú‚îÄ‚îÄ references         <- Data dictionaries, manuals, and all other explanatory materials.
‚îÇ
‚îú‚îÄ‚îÄ reports            <- Generated analysis as HTML, PDF, LaTeX, etc.
‚îÇ   ‚îî‚îÄ‚îÄ figures        <- Generated graphics and figures to be used in reporting
‚îÇ
‚îú‚îÄ‚îÄ requirements.txt   <- The requirements file for reproducing the analysis environment, e.g.
‚îÇ                         generated with `pip freeze > requirements.txt`
‚îÇ
‚îú‚îÄ‚îÄ setup.cfg          <- Configuration file for flake8
‚îÇ
‚îî‚îÄ‚îÄ clustering_workflow_engine   <- Source code for use in this project.
    ‚îÇ
    ‚îú‚îÄ‚îÄ __init__.py             <- Makes ai_workflow_engine a Python module
    ‚îÇ
    ‚îú‚îÄ‚îÄ config.py               <- Store useful variables and configuration
    ‚îÇ
    ‚îú‚îÄ‚îÄ dataset.py              <- Scripts to download or generate data
    ‚îÇ
    ‚îú‚îÄ‚îÄ experiments                
    ‚îÇ   ‚îî‚îÄ‚îÄ mlflow_utils.py     <- Utilities for MLflow integration: functions to start experiments, log parameters, metrics, and trained models
    ‚îÇ
    ‚îú‚îÄ‚îÄ features.py             <- Code to create features for modeling
    ‚îÇ
    ‚îú‚îÄ‚îÄ modeling                
    ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py 
    ‚îÇ   ‚îú‚îÄ‚îÄ predict.py              <- Code to run model inference with trained models          
    ‚îÇ   ‚îú‚îÄ‚îÄtrain.py                 <- High-level script to train models, handle datasets, and orchestrate the training pipeline
    ‚îÇ   ‚îú‚îÄ‚îÄtrainer.py               <- Functions to train models, perform cross-validation, and log parameters, metrics, and models to MLflow
    ‚îÇ   ‚îî‚îÄ‚îÄ hyperparam_optimization.py <- Functions to perform hyperparameter optimization using Optuna
    ‚îÇ
    ‚îú‚îÄ‚îÄ pipeline.py             <- High-level pipeline script to run the full workflow: data preprocessing, model training, hyperparameter optimization, evaluation, and MLflow logging
    ‚îî‚îÄ‚îÄ plots.py                <- Code to create visualizations
```

# Pipeline de Treinamento de Modelos com MLflow

Projeto b√°sico de Rede Neural Artificial (RNA) desenvolvido em **PyTorch** para fins de aprendizado e experimenta√ß√£o com pipelines de *deep learning*.  
O objetivo √© construir, treinar e avaliar uma rede simples utilizando dados sint√©ticos com suporte a *logging* e *monitoramento* estruturado, utilizando  `Optuna` e `MLflow`.


O pipeline est√° estruturado para ser executado via terminal, usando Typer, com todos os par√¢metros em **kebab-case**.

---
# Executando o pipeline
## Comando base
```bash
python pipeline.py [OPTIONS]
```

## ‚öôÔ∏è Op√ß√µes principais

| Par√¢metro        | Tipo | Padr√£o          | Descri√ß√£o                                                                 |
| ---------------- | ---- | --------------- | ------------------------------------------------------------------------- |
| `--dataset-name` | str  | "air_passengers"| Nome do dataset dispon√≠vel em `dataset.py` ou no diret√≥rio `data/`       |
| `--model-type`   | str  | "Prophet"       | Tipo de modelo a ser treinado: `"Prophet"` ou `"Arima"`                   |
| `--optimize-params` | bool | False         | Se `True`, executa otimiza√ß√£o de hiperpar√¢metros com Optuna              |
| `--n-trials`     | int  | 20              | N√∫mero de itera√ß√µes da otimiza√ß√£o (usado quando `--optimize-params=True`) |
| `--task`         | str  | "forecasting"   | Tipo de tarefa do pipeline (atualmente `"forecasting"`)                  |

> ‚ö†Ô∏è **Importante:** use **kebab-case** no terminal (`--dataset-name`) e **n√£o** `snake_case` (`--dataset_name`).

---

## üöÄ Exemplos de execu√ß√£o

| Dataset         | Modelo     | Comando                                                                                     |
| ---------------- | ----------- | ------------------------------------------------------------------------------------------- |
| Air Passengers   | Prophet    | `python -m forecasting_workflow_engine.modeling.train --dataset-name air_passengers --model-type Prophet` |
| Air Passengers   | AutoARIMA  | `python -m forecasting_workflow_engine.modeling.train --dataset-name air_passengers --model-type Arima` |
| Air Passengers   | Prophet (otimizado) | `python -m forecasting_workflow_engine.modeling.train --dataset-name air_passengers --model-type Prophet --optimize-params True --n-trials 20` |
| Air Passengers   | AutoARIMA (via pipeline) | `python -m forecasting_workflow_engine.pipelines.pipeline --dataset-name air_passengers --model-type Arima` |

---

## üí° Dica
Se preferir rodar todos os experimentos em sequ√™ncia e registrar automaticamente no MLflow:

```bash
python -m forecasting_workflow_engine.pipelines.pipeline --dataset-name air_passengers --model-type Prophet

> ‚ö†Ô∏è Importante: Use kebab-case no terminal (--dataset-name) e n√£o snake_case (--dataset_name).

## Refer√™ncias

### T√©cnicas de Forecasting
1. Witten, I. H., Frank, E., Hall, M. A., & Pal, C. J. (2016). *Data Mining: Practical Machine Learning Tools and Techniques* (4th Edition). Morgan Kaufmann.  
2. Han, J., Kamber, M., & Pei, J. (2011). *Data Mining: Concepts and Techniques* (3rd Edition). Morgan Kaufmann.  
3. Russell, S., & Norvig, P. (2021). *Artificial Intelligence: A Modern Approach* (4th Edition). Pearson.  
4. G√©ron, A. (2022). *Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow* (3rd Edition). O‚ÄôReilly Media.

### Otimiza√ß√£o de Hiperpar√¢metros (Optuna)
5. Akiba, T., Sano, S., Yanase, T., Ohta, T., & Koyama, M. (2019). *Optuna: A Next-generation Hyperparameter Optimization Framework*. Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining (KDD‚Äô19).  
6. [Optuna Official Documentation](https://optuna.org/)

### MLflow
7. Zaharia, M., Chen, A., Davidson, A., Ghodsi, A., Hong, M., Konwinski, A., ‚Ä¶ & Stoica, I. (2018). *Accelerating the Machine Learning Lifecycle with MLflow*. IEEE Data Engineering Bulletin.  
8. [MLflow Official Documentation](https://mlflow.org/)
